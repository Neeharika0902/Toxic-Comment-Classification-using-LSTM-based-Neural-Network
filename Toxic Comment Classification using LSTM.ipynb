{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.3 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully!\n",
      "Train Dataset Sample:\n",
      "   id                                               text  toxicity  \\\n",
      "0   0  This is so cool. It's like, 'would you want yo...  0.000000   \n",
      "1   1  Thank you!! This would make my life a lot less...  0.000000   \n",
      "2   2  This is such an urgent design problem; kudos t...  0.000000   \n",
      "3   3  Is this something I'll be able to install on m...  0.000000   \n",
      "4   4               haha you guys are a bunch of losers.  0.893617   \n",
      "\n",
      "   severe_toxicity  obscene  threat   insult  identity_attack  sexual_explicit  \n",
      "0         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "1         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "2         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "3         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "4         0.021277      0.0     0.0  0.87234         0.021277              0.0  \n",
      "\n",
      "Text Dataset Sample:\n",
      "   id                                               text\n",
      "0   0  [ Integrity means that you pay your debts.]\\n\\...\n",
      "1   1  This is malfeasance by the Administrator and t...\n",
      "2   2  @Rmiller101 - Spoken like a true elitist. But ...\n",
      "3   3  Paul: Thank you for your kind words.  I do, in...\n",
      "4   4  Sorry you missed high school. Eisenhower sent ...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "# Update the paths with your file locations\n",
    "train_data_path = \"train.csv\"\n",
    "text_data_path = \"test.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    text_df = pd.read_csv(text_data_path)\n",
    "  #  train_df = pd.read_csv(train_data_path).sample(1500000, random_state=42)  \n",
    "  # text_df = pd.read_csv(text_data_path).sample(70000, random_state=42)\n",
    "    \n",
    "    print(\"Datasets loaded successfully!\")\n",
    "    \n",
    "    # Displaying a preview of the datasets\n",
    "    print(\"Train Dataset Sample:\")\n",
    "    print(train_df.head())\n",
    "\n",
    "    print(\"\\nText Dataset Sample:\")\n",
    "    print(text_df.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97320, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally drop null or long entries\n",
    "train_df = train_df.dropna(subset=['text'])\n",
    "train_df = train_df[train_df['text'].str.len() <= 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity           185933.109257\n",
      "severe_toxicity      8270.111023\n",
      "obscene             25046.614174\n",
      "threat              16805.671660\n",
      "insult             146470.335207\n",
      "identity_attack     40854.609440\n",
      "sexual_explicit     11922.950046\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check label distribution\n",
    "print(train_df[['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit']].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Train Dataset Sample:\n",
      "   id                                               text  toxicity  \\\n",
      "0   0  this is so cool its like would you want your m...  0.000000   \n",
      "1   1  thank you this would make my life a lot less a...  0.000000   \n",
      "2   2  this is such an urgent design problem kudos to...  0.000000   \n",
      "3   3  is this something ill be able to install on my...  0.000000   \n",
      "4   4                haha you guys are a bunch of losers  0.893617   \n",
      "\n",
      "   severe_toxicity  obscene  threat   insult  identity_attack  sexual_explicit  \n",
      "0         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "1         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "2         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "3         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
      "4         0.021277      0.0     0.0  0.87234         0.021277              0.0  \n",
      "\n",
      "Cleaned Test Dataset Sample:\n",
      "   id                                               text\n",
      "0   0  integrity means that you pay your debts does t...\n",
      "1   1  this is malfeasance by the administrator and t...\n",
      "2   2  rmiller spoken like a true elitist but look ou...\n",
      "3   3  paul thank you for your kind words i do indeed...\n",
      "4   4  sorry you missed high school eisenhower sent t...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):  # Check if the text is a string\n",
    "        return \"\"\n",
    "    # Remove non-alphanumeric characters (retain only letters and spaces)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning to both datasets\n",
    "if 'text' in train_df.columns:\n",
    "    train_df['text'] = train_df['text'].apply(clean_text)\n",
    "else:\n",
    "    print(\"Column 'text' not found in train.csv\")\n",
    "\n",
    "if 'text' in text_df.columns:\n",
    "    text_df['text'] = text_df['text'].apply(clean_text)\n",
    "else:\n",
    "    print(\"Column 'text' not found in test.csv\")\n",
    "\n",
    "# Display cleaned data samples\n",
    "print(\"Cleaned Train Dataset Sample:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nCleaned Test Dataset Sample:\")\n",
    "print(text_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        # Ensure compatibility with both Pandas and NumPy objects\n",
    "        if isinstance(texts, pd.Series):\n",
    "            self.texts = texts.reset_index(drop=True)\n",
    "        else:\n",
    "            self.texts = texts  # Assume it's already indexable (e.g., NumPy array or list)\n",
    "        \n",
    "        if isinstance(labels, pd.Series):\n",
    "            self.labels = labels.reset_index(drop=True)\n",
    "        else:\n",
    "            self.labels = labels  # Assume it's already indexable (e.g., NumPy array or list)\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Fetch the text and label at the given index\n",
    "            text = self.texts[idx]\n",
    "            label = self.labels[idx]\n",
    "\n",
    "            # Tokenize the text\n",
    "            tokens = self.tokenizer(\n",
    "                text, \n",
    "                max_length=self.max_length, \n",
    "                padding='max_length', \n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                'input_ids': tokens['input_ids'].squeeze(0),\n",
    "                'attention_mask': tokens['attention_mask'].squeeze(0),\n",
    "                'labels': torch.tensor(label, dtype=torch.float)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {idx}: {e}\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer using TorchText\n",
    "from transformers import AutoTokenizer  # Hugging Face tokenizer for simplicity\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", vocab_size=5000)  # Using tokenizer, not pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "X = train_df['text']\n",
    "y = train_df[['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature matrix:\n",
      "Target variable sample:\n",
      "   toxicity  severe_toxicity  obscene  threat   insult  identity_attack  \\\n",
      "0  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
      "1  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
      "2  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
      "3  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
      "4  0.893617         0.021277      0.0     0.0  0.87234         0.021277   \n",
      "\n",
      "   sexual_explicit  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              0.0  \n",
      "3              0.0  \n",
      "4              0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'train_df' contains the training dataset\n",
    "# Extract features and target variables\n",
    "X = train_df['text']  # Text data\n",
    "y = train_df[['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit']]  # Labels\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Transform text into numerical vectors\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Convert TF-IDF features to a DataFrame (optional)\n",
    "# xX_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(\"TF-IDF feature matrix:\")\n",
    "# print(X_tfidf.head())\n",
    "\n",
    "# Labels remain unchanged\n",
    "print(\"Target variable sample:\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape[1] 7\n",
      "Length of X: 1804859\n",
      "Length of y: 1804859\n",
      "DataLoaders are ready!\n"
     ]
    }
   ],
   "source": [
    "y = train_df[['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit']].values\n",
    "\n",
    "print('y.shape[1]',y.shape[1])\n",
    "# Ensure consistent sizes (no need to align lengths manually, as there's no SMOTE-induced imbalance)\n",
    "print(f\"Length of X: {len(X)}\")\n",
    "print(f\"Length of y: {len(y)}\")\n",
    "\n",
    "# Binarize multi-label targets if necessary\n",
    "#print(f\"y shape before binarization: {y.shape}\")\n",
    "#mlb = MultiLabelBinarizer()\n",
    "#y = mlb.fit_transform(y)\n",
    "#print(f\"y shape after binarization: {y.shape}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a function for batched tokenization\n",
    "def tokenize_batch(texts, tokenizer, max_length=128):\n",
    "    \"\"\"Tokenize a batch of texts.\"\"\"\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return tokens[\"input_ids\"], tokens[\"attention_mask\"]\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "train_dataset = CommentDataset(X_train, y_train, tokenizer, max_length=128)\n",
    "val_dataset = CommentDataset(X_val, y_val, tokenizer, max_length=128)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "print(\"DataLoaders are ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated forward Method in the LSTM Model\n",
    "Modify the forward method of your LSTMClassifier to apply mean pooling over the sequence outputs, ensuring that the model outputs exactly 7 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels, num_layers, dropout_rate):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        # Normalization\n",
    "        self.ln = nn.LayerNorm(hidden_dim * 2)\n",
    "        \n",
    "        # Attention Layer\n",
    "        self.attention = nn.Linear(hidden_dim * 2, hidden_dim * 2)  # Self-attention layer\n",
    "        self.attention_weights = nn.Linear(hidden_dim * 2, 1)  # Attention weights computation\n",
    "        \n",
    "        # Dropout Layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n",
    "        \n",
    "        # Sigmoid Activation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # Embedding Layer\n",
    "        embedded = self.embedding(input_ids)  # Shape: [batch_size, seq_length, embed_dim]\n",
    "        \n",
    "        # LSTM Layer\n",
    "        lstm_out, _ = self.lstm(embedded)  # Shape: [batch_size, seq_length, hidden_dim * 2]\n",
    "\n",
    "        # Apply Layer Normalization\n",
    "        lstm_out = self.ln(lstm_out)\n",
    "        \n",
    "        # Attention Mechanism\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.tanh(self.attention(lstm_out))  # Shape: [batch_size, seq_length, hidden_dim * 2]\n",
    "        attn_weights = torch.softmax(self.attention_weights(attn_scores), dim=1)  # Shape: [batch_size, seq_length, 1]\n",
    "        \n",
    "        # Compute the context vector\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)  # Shape: [batch_size, hidden_dim * 2]\n",
    "        \n",
    "        # Dropout\n",
    "        context = self.dropout(context)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        out = self.fc(context)  # Shape: [batch_size, num_labels]\n",
    "        \n",
    "        # Sigmoid Activation\n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 200  # Embedding dimension\n",
    "hidden_dim = 256  # Hidden layer size in LSTM\n",
    "num_labels = y.shape[1]  # Number of output labels\n",
    "num_layers = 3  # Reduce layers as attention reduces the need for deeper stacks\n",
    "dropout_rate = 0.5  # Dropout rate for regularization\n",
    "\n",
    "# Model Initialization\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_labels=num_labels,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#  Learning Rate Scheduler -----------------------------------------------------------------\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute F1-score for multi-label classification.\n",
    "    Args:\n",
    "        outputs: Model's predicted probabilities (continuous values between 0 and 1).\n",
    "        labels: Ground truth labels (binary values 0 or 1).\n",
    "    Returns:\n",
    "        Weighted F1-score.\n",
    "    \"\"\"\n",
    "    # Threshold the predictions to convert probabilities to binary\n",
    "    preds = (outputs > 0.4).float()  # Convert probabilities to binary predictions (0 or 1)\n",
    "\n",
    "    # Ensure shapes are compatible\n",
    "    if preds.dim() > 2:\n",
    "        preds = preds.squeeze()  # Remove extra dimensions if present\n",
    "    if labels.dim() > 2:\n",
    "        labels = labels.squeeze()  # Remove extra dimensions if present\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    labels = labels.cpu().numpy().astype(int)  # Cast labels to integer type\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    # Debugging: Check shapes and data types\n",
    "    # print(f\"Labels shape: {labels.shape}, Predictions shape: {preds.shape}\")\n",
    "    # print(f\"Labels type: {labels.dtype}, Predictions type: {preds.dtype}\")\n",
    "\n",
    "    # Ensure the shapes match\n",
    "    if labels.shape != preds.shape:\n",
    "        raise ValueError(f\"Shape mismatch: Labels shape {labels.shape}, Predictions shape {preds.shape}\")\n",
    "\n",
    "    # Compute F1-score\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\", zero_division=0)\n",
    "    return f1\n",
    "\n",
    "\n",
    "\n",
    "# Training loop -----------------------------------------------------------------------------------\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient Clipping to prevent exploding gradients during backpropagation\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Validation Step -----------------------------------------------------------------\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_f1 = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Compute F1-score\n",
    "                val_f1 += compute_metrics(outputs, labels)\n",
    "        \n",
    "        # Average validation metrics\n",
    "        val_loss /= len(val_loader)\n",
    "        val_f1 /= len(val_loader)\n",
    "        print(f\"Validation Loss: {val_loss}, Validation F1-Score: {val_f1}\")\n",
    "\n",
    "        # Scheduler calling -----------------------------------------------------------------\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early Stopping ------------------------------------------------------------------------------------------\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), '5_12_best_model.pt')  # Save best model\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.0975636530576633\n",
      "Validation Loss: 0.09342526657007168, Validation F1-Score: 0.020238253539082412\n",
      "Epoch 2/10, Training Loss: 0.09307151174394085\n",
      "Validation Loss: 0.09289755528567514, Validation F1-Score: 0.02051221978086924\n",
      "Epoch 3/10, Training Loss: 0.0920022297384367\n",
      "Validation Loss: 0.09303225609367174, Validation F1-Score: 0.019726448858579545\n",
      "Epoch 4/10, Training Loss: 0.09145476368593786\n",
      "Validation Loss: 0.0931353644927504, Validation F1-Score: 0.02040622847546301\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "# Define optimizer AdamW\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_model(\n",
    "    model=model,  # Your model instance\n",
    "    train_loader=train_loader,  # Training data loader\n",
    "    val_loader=val_loader,  # Validation data loader\n",
    "    criterion=criterion,  # Loss function\n",
    "    optimizer=optimizer,  # Optimizer\n",
    "    scheduler=scheduler,  # Learning rate scheduler\n",
    "    num_epochs=10,  # Total number of epochs\n",
    "    patience=2  # Early stopping patience\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trail for different threshold To find best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, F1-score: 0.0163\n",
      "Threshold: 0.2, F1-score: 0.0250\n",
      "Threshold: 0.30000000000000004, F1-score: 0.0332\n",
      "Threshold: 0.4, F1-score: 0.0407\n",
      "Threshold: 0.5, F1-score: 0.0464\n",
      "Threshold: 0.6, F1-score: 0.0452\n",
      "Threshold: 0.7000000000000001, F1-score: 0.0306\n",
      "Threshold: 0.8, F1-score: 0.0079\n",
      "Threshold: 0.9, F1-score: 0.0000\n",
      "Best Threshold: 0.5, Best F1-score: 0.0464\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def tune_threshold(model, data_loader):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)  # Test thresholds from 0.1 to 0.9\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        total_preds = []\n",
    "        total_labels = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "\n",
    "                # Apply current threshold\n",
    "                predictions = (outputs > threshold).float()\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                total_preds.append(predictions.cpu().numpy())\n",
    "                total_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        # Flatten lists\n",
    "        total_preds = np.vstack(total_preds)\n",
    "        total_labels = np.vstack(total_labels)\n",
    "\n",
    "        # Ensure both are binary (int type)\n",
    "        total_preds = total_preds.astype(int)  # Convert predictions to int\n",
    "        total_labels = total_labels.astype(int)  # Ensure labels are also int\n",
    "\n",
    "        # Calculate F1-score\n",
    "        f1 = f1_score(total_labels, total_preds, average=\"weighted\", zero_division=0)\n",
    "        print(f\"Threshold: {threshold}, F1-score: {f1:.4f}\")\n",
    "\n",
    "        # Update best threshold\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"Best Threshold: {best_threshold}, Best F1-score: {best_f1:.4f}\")\n",
    "    return best_threshold\n",
    "\n",
    "# Tune threshold\n",
    "best_threshold = tune_threshold(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 86.97%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, data_loader, threshold=0.6):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            # Apply threshold to predictions (e.g., 0.5 for binary classification)\n",
    "            predictions = (outputs > threshold).float()\n",
    "\n",
    "            # Calculate number of correct predictions\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.numel()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# Calculate and print the validation accuracy\n",
    "val_accuracy = calculate_accuracy(model, val_loader)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions for the test dataset (kaggle submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Step 1: Define the prediction function\n",
    "def generate_predictions(model, tokenizer, test_texts, max_length=256):\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for text in test_texts:\n",
    "            # Tokenize the input text\n",
    "            tokens = tokenizer(\n",
    "                text,\n",
    "                max_length=max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_ids = tokens[\"input_ids\"].to(device)\n",
    "            attention_mask = tokens[\"attention_mask\"].to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(input_ids, attention_mask)  # Shape: [batch_size, 7]\n",
    "            probabilities = outputs.squeeze().cpu().numpy()  # Convert to NumPy array\n",
    "            \n",
    "            # Convert probabilities to binary predictions\n",
    "            binary_predictions = (probabilities > 0.5).astype(int)\n",
    "            predictions.append(binary_predictions.tolist())\n",
    "    return predictions\n",
    "\n",
    "# Step 2: Load test dataset and generate predictions\n",
    "test_texts = text_df['text'].tolist()  # Extract text data from the test dataset\n",
    "test_ids = text_df['id'].tolist()  # Extract IDs from the test dataset\n",
    "\n",
    "# Generate predictions using the trained model\n",
    "test_predictions = generate_predictions(model, tokenizer, test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to 5_12_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create the submission DataFrame\n",
    "submission_columns = ['id', 'toxicity', 'severe_tox', 'obscene', 'threat', 'insult', 'identity_att', 'sexual_explicit']\n",
    "submission_df = pd.DataFrame(test_predictions, columns=submission_columns[1:])  # Add predictions\n",
    "submission_df.insert(0, 'id', test_ids)  # Add the `id` column from the test dataset\n",
    "\n",
    "# Step 4: Save predictions to a CSV file\n",
    "submission_file_path = '5_12_submission.csv'\n",
    "submission_df.to_csv(submission_file_path, index=False)\n",
    "print(f\"Submission file saved to {submission_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9910482,
     "sourceId": 87217,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30788,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
